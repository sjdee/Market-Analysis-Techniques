{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjdee/Market-Analysis-Techniques/blob/master/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0LhCFfyqBC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def run_classifier (pDf,minify_data,less_columns,print_data):  \n",
        "\n",
        "  \n",
        "  df = pDf\n",
        "  \n",
        "#   'day9', 'day10'\n",
        "  if(less_columns==True):\n",
        "    df = df.loc[:,['BEST_ANALYST_RATING', 'RETURN_ON_ASSET', 'BEST_TARGET_PRICE', 'CUR_MKT_CAP', 'SHORT_INT', 'TOT_BUY_REC', 'TOT_SELL_REC', 'day1','day2', 'day3', 'day4','day5', 'day6','day7', 'day8']]\n",
        "    df.dropna(inplace=True)\n",
        "    features = df.iloc[:,0:-8]\n",
        "    labels = df.iloc[:,-8:]\n",
        "    \n",
        "  else:\n",
        "    df.dropna(inplace=True)\n",
        "    features = df.iloc[:,5:-12]\n",
        "    labels = df.iloc[:,-10:]\n",
        "    \n",
        "    \n",
        "  print(df.shape)\n",
        "  report_data = []\n",
        "\n",
        "\n",
        "  for i in range(len(labels.columns)):\n",
        "    # specify the feature set, target set, the test size and random_state to select records randomly\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels.iloc[:,i], test_size=0.3,random_state=0) \n",
        "\n",
        "    # Scaling values in the feature set\n",
        "    scaling = MinMaxScaler(feature_range=(0,1)).fit(X_train)\n",
        "    X_train = scaling.transform(X_train)\n",
        "    X_test = scaling.transform(X_test)\n",
        "\n",
        "\n",
        "    # Create a svm Classifier\n",
        "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "    # Train the model using the training sets\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the response for test dataset\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred) \n",
        "    \n",
        "    f1_scores =[] \n",
        "    f1_scores.insert(0, metrics.f1_score(y_test, y_pred, average='macro'))\n",
        "    f1_scores.insert(1, metrics.f1_score(y_test, y_pred, average='micro'))\n",
        "    f1_scores.insert(2, metrics.f1_score(y_test, y_pred, average='weighted'))\n",
        "    \n",
        "    if(print_data==True):\n",
        "      print(labels.iloc[:,i].name)\n",
        "      print(accuracy)\n",
        "      print(report)\n",
        "    else:\n",
        "      accumulate_data(report_data,report,accuracy,labels.iloc[:,i].name,\"SVM\",minify_data,f1_scores)\n",
        "\n",
        "  return report_data       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjCu8rGxeEjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accumulate_data(report_data,report,accuracy,day_name,model_name,minify_data,f1_scores):\n",
        "      \n",
        "    \n",
        "  print(day_name)\n",
        "  print(report)\n",
        "  \n",
        "  if(minify_data == True):\n",
        "\n",
        "    row = {}\n",
        "    row['day'] = day_name.replace(\"day\", \"\") \n",
        "    row['accuracy'] = accuracy\n",
        "    row['f1score_macro'] = f1_scores[0]\n",
        "    row['f1score_micro'] = f1_scores[1]\n",
        "    row['f1score_weigthed'] = f1_scores[2]\n",
        "    # row['model'] = model_name\n",
        "\n",
        "    # unravel report for the given day       \n",
        "    lines = report.split('\\n')\n",
        "    for line in lines[2:-5]:\n",
        "\n",
        "      row_data = line.split('     ')\n",
        "\n",
        "      # update recall for sell\n",
        "      if(float(row_data[1])==0.0):\n",
        "        row['sell_recall']= float(row_data[3])\n",
        "      # update precison for buy\n",
        "      if(float(row_data[1])==2.0):\n",
        "        row['buy_precison']= float(row_data[2])\n",
        "\n",
        "    report_data.append(row)\n",
        "\n",
        "\n",
        "  else:    \n",
        "    lines = report.split('\\n')\n",
        "    for line in lines[2:-5]:\n",
        "        row = {}\n",
        "        row_data = line.split('     ')\n",
        "        row['model'] = model_name\n",
        "        row['accuracy'] = accuracy\n",
        "        row['day'] = labels.iloc[:,i].name\n",
        "        row['class'] = row_data[1]\n",
        "        row['precision'] = float(row_data[2])\n",
        "        row['recall'] = float(row_data[3])\n",
        "        row['f1_score'] = float(row_data[4])\n",
        "        row['support'] = float(row_data[5])\n",
        "        report_data.append(row)\n",
        "\n",
        "  return report_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1b8gg7HqYRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sectors = ['Communication Services', 'Consumer Discretionary','Consumer Staples', 'Energy', 'Financials', 'Health Care', 'Industrials', 'Information Technology', 'Materials', 'Real Estate', 'Utilities']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdXr_4QKtJXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file_id = '18pa4iuqvz2SX5RYrUdn09bDU8eNm2hqI'\n",
        "\n",
        "# 2. Load a file by ID \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('sp500_transformation_input.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKqChAeytSYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('sp500_transformation_input.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llJkpH4liI_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.set_index('Sector', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkqFgl1-VT6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_each_sector = False\n",
        "less_columns = True\n",
        "minify = True\n",
        "print_data = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYPv6SUQtbsW",
        "colab_type": "code",
        "outputId": "ede4cdce-ecd1-40fe-a05f-d38e69cb629f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1434
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "if(check_each_sector == True):\n",
        "   \n",
        "  for k in range(len(sectors)):\n",
        "    print('Running classifier by sector.')\n",
        "\n",
        "    df_sectorised = df.loc[sectors[k]]\n",
        "    \n",
        "    report = run_classifier(df_sectorised,minify,less_columns,print_data)\n",
        "\n",
        "    \n",
        "    dataframe = pd.DataFrame.from_dict(report)\n",
        "    file_name = sectors[k]+'SVM_classification_report.csv'\n",
        "    dataframe.to_csv(file_name, index = False)\n",
        "#     files.download(file_name)\n",
        "    \n",
        "else:\n",
        "  print('Running classifier on all.')\n",
        "  \n",
        "  report = run_classifier(df,minify,less_columns,print_data)\n",
        "\n",
        "  dataframe = pd.DataFrame.from_dict(report)\n",
        "  dataframe.to_csv('SVM_classification_report.csv', index = False)\n",
        "  files.download('SVM_classification_report.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running classifier on all.\n",
            "(420739, 15)\n",
            "day1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00     52535\n",
            "         2.0       0.58      1.00      0.74     73687\n",
            "\n",
            "    accuracy                           0.58    126222\n",
            "   macro avg       0.29      0.50      0.37    126222\n",
            "weighted avg       0.34      0.58      0.43    126222\n",
            "\n",
            "day2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      1.00      0.84     91528\n",
            "         2.0       0.00      0.00      0.00     34694\n",
            "\n",
            "    accuracy                           0.73    126222\n",
            "   macro avg       0.36      0.50      0.42    126222\n",
            "weighted avg       0.53      0.73      0.61    126222\n",
            "\n",
            "day3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      1.00      0.81     86012\n",
            "         2.0       0.00      0.00      0.00     40210\n",
            "\n",
            "    accuracy                           0.68    126222\n",
            "   macro avg       0.34      0.50      0.41    126222\n",
            "weighted avg       0.46      0.68      0.55    126222\n",
            "\n",
            "day4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      1.00      0.79     82085\n",
            "         2.0       0.00      0.00      0.00     44137\n",
            "\n",
            "    accuracy                           0.65    126222\n",
            "   macro avg       0.33      0.50      0.39    126222\n",
            "weighted avg       0.42      0.65      0.51    126222\n",
            "\n",
            "day5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      1.00      0.77     79267\n",
            "         2.0       0.00      0.00      0.00     46955\n",
            "\n",
            "    accuracy                           0.63    126222\n",
            "   macro avg       0.31      0.50      0.39    126222\n",
            "weighted avg       0.39      0.63      0.48    126222\n",
            "\n",
            "day6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      1.00      0.76     77271\n",
            "         2.0       0.00      0.00      0.00     48951\n",
            "\n",
            "    accuracy                           0.61    126222\n",
            "   macro avg       0.31      0.50      0.38    126222\n",
            "weighted avg       0.37      0.61      0.46    126222\n",
            "\n",
            "day7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      1.00      0.75     75466\n",
            "         2.0       0.00      0.00      0.00     50756\n",
            "\n",
            "    accuracy                           0.60    126222\n",
            "   macro avg       0.30      0.50      0.37    126222\n",
            "weighted avg       0.36      0.60      0.45    126222\n",
            "\n",
            "day8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      1.00      0.74     73835\n",
            "         2.0       0.00      0.00      0.00     52387\n",
            "\n",
            "    accuracy                           0.58    126222\n",
            "   macro avg       0.29      0.50      0.37    126222\n",
            "weighted avg       0.34      0.58      0.43    126222\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}